{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import retinanet_config as config\n",
    "from bs4 import BeautifulSoup\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "args = easydict.EasyDict({\n",
    "        \"annotations\": config.ANNOT_PATH,\n",
    "        \"images\": config.IMAGES_PATH,\n",
    "        \"train\": config.TRAIN_CSV,\n",
    "        \"test\": config.TEST_CSV,\n",
    "        \"classes\": config.CLASSES_CSV,\n",
    "        \"split\": config.TRAIN_TEST_SPLIT\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annot_path = args[\"annotations\"]\n",
    "images_path = args[\"images\"]\n",
    "train_csv = args[\"train\"]\n",
    "test_csv = args[\"test\"]\n",
    "classes_csv = args[\"classes\"]\n",
    "train_test_split = args[\"split\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imagePaths = list(paths.list_files(images_path))\n",
    "random.shuffle(imagePaths)\n",
    "i = int(len(imagePaths) * train_test_split)\n",
    "trainImagePaths = imagePaths[:i]\n",
    "testImagePaths = imagePaths[i:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "print(i)\n",
    "print(int(len(imagePaths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = [ (\"train\", trainImagePaths, train_csv),\n",
    "(\"test\", testImagePaths, test_csv)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the set of classes we have\n",
    "CLASSES = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating 'train' set...\n",
      "[INFO] 63 total images in 'train' set\n",
      "[INFO] creating 'test' set...\n",
      "[INFO] 22 total images in 'test' set\n",
      "[INFO] writing classes...\n"
     ]
    }
   ],
   "source": [
    "# loop over the datasets\n",
    "for (dType, imagePaths, outputCSV) in dataset:\n",
    " \n",
    "    print (\"[INFO] creating '{}' set...\".format(dType))\n",
    "    print (\"[INFO] {} total images in '{}' set\".format(len(imagePaths), dType))\n",
    "\n",
    "   \n",
    "    csv = open(outputCSV, \"w\")\n",
    "\n",
    "    # loop over the image paths\n",
    "    for imagePath in imagePaths:\n",
    "        # build the corresponding annotation path\n",
    "        fname = imagePath.split(os.path.sep)[-1]\n",
    "        fname = \"{}.xml\".format(fname[:fname.rfind(\".\")])\n",
    "        annotPath = os.path.sep.join([annot_path, fname])\n",
    "\n",
    "        # load the contents of the annotation file and buid the soup\n",
    "        contents = open(annotPath).read()\n",
    "        soup = BeautifulSoup(contents, \"html.parser\")\n",
    "\n",
    "        # extract the image dimensions\n",
    "        w = int(soup.find(\"width\").string)\n",
    "        h = int(soup.find(\"height\").string)\n",
    "\n",
    "        # loop over all object elements\n",
    "        for o in soup.find_all(\"object\"):\n",
    "            #extract the label and bounding box coordinates\n",
    "            label = o.find(\"name\").string\n",
    "            xMin = int(float(o.find(\"xmin\").string))\n",
    "            yMin = int(float(o.find(\"ymin\").string))\n",
    "            xMax = int(float(o.find(\"xmax\").string))\n",
    "            yMax = int(float(o.find(\"ymax\").string))\n",
    "\n",
    "          \n",
    "            xMin = max(0, xMin)\n",
    "            yMin = max(0, yMin)\n",
    "            xMax = min(w, xMax)\n",
    "            yMax = min(h, yMax)\n",
    "\n",
    "           \n",
    "            if xMin >= xMax or yMin >= yMax:\n",
    "                continue\n",
    "            elif xMax <= xMin or yMax <= yMin:\n",
    "                continue\n",
    "\n",
    "            # write the image path, bb coordinates, label to the output CSV\n",
    "            row = [os.path.abspath(imagePath),str(xMin), str(yMin), str(xMax),\n",
    "                    str(yMax), str(label)]\n",
    "            csv.write(\"{}\\n\".format(\",\".join(row)))\n",
    "\n",
    "            # update the set of unique class labels\n",
    "            CLASSES.add(label)\n",
    "\n",
    "  \n",
    "    csv.close()\n",
    "\n",
    "# write the classes to file\n",
    "print(\"[INFO] writing classes...\")\n",
    "csv = open(classes_csv, \"w\")\n",
    "rows = [\",\".join([c, str(i)]) for (i,c) in enumerate(CLASSES)]\n",
    "csv.write(\"\\n\".join(rows))\n",
    "csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'car'}\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below code section was written to train the model in a different way but this option also did not work. Can be used in future for improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/user1/.virtualenvs/sdc_virtualenv/lib/python3.6/site-packages (4.1.0.25)\r\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/user1/.virtualenvs/sdc_virtualenv/lib/python3.6/site-packages (from opencv-python) (1.16.4)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "#import os\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#!pip install opencv-python\n",
    "#import cv2\n",
    "\n",
    "#import keras\n",
    "\n",
    "#import tensorflow as tf\n",
    "#from tensorflow.keras.datasets import cifar10\n",
    "#from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#from keras_retinanet import models\n",
    "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "#from tensorflow.keras.callbacks import TensorBoard\n",
    "#import pickle\n",
    "#import time\n",
    "#import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_session():\n",
    "#    config = tf.ConfigProto()\n",
    "#    config.gpu_options.allow_growth = True\n",
    "#    return tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.backend.tensorflow_backend.set_session(get_session())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes = 15\n",
    "\n",
    "\n",
    "#from keras_retinanet.models.resnet import ResNetBackbone\n",
    "#model = ResNetBackbone('resnet50').retinanet(num_classes)\n",
    "#model.load_weights('/home/user1/Desktop/sdc_project/megha_retinanet/resnet50_coco_best_v2.1.0.h5', by_name=True, skip_mismatch=True)\n",
    "\n",
    "#model.compile(\n",
    " #       loss={\n",
    "  #          'regression'    : '/home/user1/Desktop/sdc_project/megha_retinanet/keras-retinanet/keras_retinanet.losses.smooth_l1()',\n",
    "   #         'classification': '/home/user1/Desktop/sdc_project/megha_retinanet/keras-retinanet/keras_retinanet.losses.focal()'\n",
    "    #        \n",
    "     #   },\n",
    "      #  optimizer=keras.optimizers.adam(lr=1e-4, clipnorm=0.001),\n",
    "    #) \n",
    "\n",
    "#model.fit('/home/user1/Desktop/sdc_project/megha_retinanet/dataset/train.csv','/home/user1/Desktop/sdc_project/megha_retinanet/dataset/classes.csv', batch_size=3, epochs=5, validation_split=0.1, callbacks=['/home/user1/Desktop/sdc_project/megha_retinanet/tensorboard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model_path = os.path.join('..', '/home/user1/Desktop/sdc_project/megha_retinanet/', 'resnet50_coco_best_v2.1.0.h5')\n",
    "#model = models.load_model(model_path, backbone_name='resnet50')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_to_names ={0:'car'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.summary())\n",
    "#print(labels_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below code is to draw the boxes on the vehicles detected\n",
    "\n",
    "#from keras_retinanet import models\n",
    "#from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "#from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "#from keras_retinanet.utils.colors import label_color\n",
    "\n",
    "# import miscellaneous modules\n",
    "#import matplotlib.pyplot as plt\n",
    "#import cv2\n",
    "#import os\n",
    "#import numpy as np\n",
    "#import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image\n",
    "#image = read_image_bgr('dataset/images/video_51.png')\n",
    "\n",
    "# copy to draw on\n",
    "#draw = image.copy()\n",
    "#draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# preprocess image for network\n",
    "#image = preprocess_image(image)\n",
    "#image, scale = resize_image(image)\n",
    "\n",
    "# process image\n",
    "#start = time.time()\n",
    "#boxes, scores, labels = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "#print(\"processing time: \", time.time() - start)\n",
    "\n",
    "# correct for image scale\n",
    "#boxes /= scale\n",
    "\n",
    "# visualize detections\n",
    "#for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "    # scores are sorted so we can break\n",
    " #   if score < 0.5:\n",
    "  #      print('less than 0.5')\n",
    "   #     break\n",
    "        \n",
    "    #color = label_color(label)\n",
    "    #print(score)\n",
    "    #print(label)\n",
    "    #print(box)\n",
    "    #b = box.astype(int)\n",
    "    #draw_box(draw, b, color=color)\n",
    "    #print(labels_to_names[0])\n",
    "    #caption = \"{} {:.3f}\".format(labels_to_names[0], score)\n",
    "    #draw_caption(draw, b, caption)\n",
    "    \n",
    "#plt.figure(figsize=(15, 15))\n",
    "#plt.axis('off')\n",
    "#plt.imshow(draw)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
